{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TPC9HKieuZcs"
      },
      "source": [
        "** Image generation using GAN.**\n",
        "\n",
        "**Theory:**\n",
        "A Generative Adversarial Network (GAN) is a neural network framework composed of a generator and discriminator. The generator creates fake data, while the discriminator tries to distinguish real from fake. They compete in a training process: the generator aims to improve its fake data to fool the discriminator, while the discriminator seeks to become better at distinguishing real from fake. This adversarial training continues iteratively, ideally resulting in the generator producing data indistinguishable from real data. GANs find applications in image generation, style transfer, super-resolution, and more, making them a key technology in machine learning.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jz1_lWdxv-RE"
      },
      "source": [
        "**Algorithm-**\n",
        "\n",
        "**Initialization:**\n",
        "\n",
        "* Import necessary libraries.\n",
        "* Set device (GPU or CPU).\n",
        "* Load CIFAR-10 dataset and create a data loader.\n",
        "* Define hyperparameters.\n",
        "\n",
        "**Define Generator and Discriminator:**\n",
        "\n",
        "* Define the generator and discriminator neural networks.\n",
        "\n",
        "**Loss and Optimizers:**\n",
        "\n",
        "* Define adversarial loss.\n",
        "* Initialize optimizers for the generator and discriminator.\n",
        "\n",
        "**Training Loop:**\n",
        "\n",
        "* For each epoch:\n",
        "        Iterate over real image batches.\n",
        "* Train the discriminator:\n",
        "        Compute discriminator loss for real and fake images.\n",
        "        Update discriminator's parameters.\n",
        "*Train the generator:\n",
        "        Compute generator loss.\n",
        "        Update generator's parameters.\n",
        "        Print loss values every 100 batches.\n",
        "\n",
        "**Image Generation and Visualization:**\n",
        "\n",
        "* Generate and display fake images from the generator every 10 epochs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7pCt7c3cpPCL"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Set device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2vZb8UIUpWSL",
        "outputId": "9f380adf-5806-44c3-941d-3507fd6de81d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 170498071/170498071 [00:04<00:00, 39050121.80it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n"
          ]
        }
      ],
      "source": [
        "import torchvision.transforms as transforms\n",
        "\n",
        "# Define data transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),               # Convert PIL image or numpy array to tensor\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalize to [-1, 1]\n",
        "])\n",
        "\n",
        "# Create the CIFAR-10 dataset with the defined transformations\n",
        "train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "UcZiPV2nq8Of"
      },
      "outputs": [],
      "source": [
        "# Hyperparameters\n",
        "latent_dim = 100\n",
        "lr = 0.0002\n",
        "beta1 = 0.5\n",
        "beta2 = 0.999\n",
        "num_epochs = 2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MOzaNR0Cq-K-"
      },
      "outputs": [],
      "source": [
        "# Define the generator\n",
        "class Generator(nn.Module):\n",
        "\tdef __init__(self, latent_dim):\n",
        "\t\tsuper(Generator, self).__init__()\n",
        "\n",
        "\t\tself.model = nn.Sequential(\n",
        "\t\tnn.Linear(latent_dim, 128 * 8 * 8),\n",
        "\t\tnn.ReLU(),\n",
        "\t\tnn.Unflatten(1, (128, 8, 8)),\n",
        "\t\tnn.Upsample(scale_factor=2),\n",
        "\t\tnn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
        "\t\tnn.BatchNorm2d(128, momentum=0.78),\n",
        "\t\tnn.ReLU(),\n",
        "\t\tnn.Upsample(scale_factor=2),\n",
        "\t\tnn.Conv2d(128, 64, kernel_size=3, padding=1),\n",
        "\t\tnn.BatchNorm2d(64, momentum=0.78),\n",
        "\t\tnn.ReLU(),\n",
        "\t\tnn.Conv2d(64, 3, kernel_size=3, padding=1),\n",
        "\t\tnn.Tanh()\n",
        "\t)\n",
        "\n",
        "\tdef forward(self, z):\n",
        "\t\timg = self.model(z)\n",
        "\t\treturn img\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bFgxabWNrAqu"
      },
      "outputs": [],
      "source": [
        "# Define the discriminator\n",
        "class Discriminator(nn.Module):\n",
        "\tdef __init__(self):\n",
        "\t\tsuper(Discriminator, self).__init__()\n",
        "\n",
        "\t\tself.model = nn.Sequential(\n",
        "\t\tnn.Conv2d(3, 32, kernel_size=3, stride=2, padding=1),\n",
        "\t\tnn.LeakyReLU(0.2),\n",
        "\t\tnn.Dropout(0.25),\n",
        "\t\tnn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1),\n",
        "\t\tnn.ZeroPad2d((0, 1, 0, 1)),\n",
        "\t\tnn.BatchNorm2d(64, momentum=0.82),\n",
        "\t\tnn.LeakyReLU(0.25),\n",
        "\t\tnn.Dropout(0.25),\n",
        "\t\tnn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1),\n",
        "\t\tnn.BatchNorm2d(128, momentum=0.82),\n",
        "\t\tnn.LeakyReLU(0.2),\n",
        "\t\tnn.Dropout(0.25),\n",
        "\t\tnn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
        "\t\tnn.BatchNorm2d(256, momentum=0.8),\n",
        "\t\tnn.LeakyReLU(0.25),\n",
        "\t\tnn.Dropout(0.25),\n",
        "\t\tnn.Flatten(),\n",
        "\t\tnn.Linear(256 * 5 * 5, 1),\n",
        "\t\tnn.Sigmoid()\n",
        "\t)\n",
        "\n",
        "\tdef forward(self, img):\n",
        "\t\tvalidity = self.model(img)\n",
        "\t\treturn validity\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iBFFF-zyrDoG"
      },
      "outputs": [],
      "source": [
        "# Define the generator and discriminator\n",
        "# Initialize generator and discriminator\n",
        "generator = Generator(latent_dim).to(device)\n",
        "discriminator = Discriminator().to(device)\n",
        "\n",
        "# Loss function\n",
        "adversarial_loss = nn.BCELoss()\n",
        "\n",
        "# Optimizers\n",
        "optimizer_G = optim.Adam(generator.parameters()\\\n",
        "\t\t\t\t\t\t, lr=lr, betas=(beta1, beta2))\n",
        "optimizer_D = optim.Adam(discriminator.parameters()\\\n",
        "\t\t\t\t\t\t, lr=lr, betas=(beta1, beta2))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NvpX_KARreSa"
      },
      "outputs": [],
      "source": [
        "dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 703
        },
        "id": "lqdzW4iGrJbW",
        "outputId": "d8155a39-f40d-4b46-fcb3-d42d59e5e566"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10]\t\t\t\t\t\tBatch 100/1563 Discriminator Loss: 0.4132 Generator Loss: 1.3078\n",
            "Epoch [1/10]\t\t\t\t\t\tBatch 200/1563 Discriminator Loss: 0.4908 Generator Loss: 1.0465\n",
            "Epoch [1/10]\t\t\t\t\t\tBatch 300/1563 Discriminator Loss: 0.6683 Generator Loss: 1.1993\n",
            "Epoch [1/10]\t\t\t\t\t\tBatch 400/1563 Discriminator Loss: 0.7209 Generator Loss: 0.8381\n",
            "Epoch [1/10]\t\t\t\t\t\tBatch 500/1563 Discriminator Loss: 0.6046 Generator Loss: 1.1491\n",
            "Epoch [1/10]\t\t\t\t\t\tBatch 600/1563 Discriminator Loss: 0.6765 Generator Loss: 0.9769\n",
            "Epoch [1/10]\t\t\t\t\t\tBatch 700/1563 Discriminator Loss: 0.7238 Generator Loss: 0.8876\n",
            "Epoch [1/10]\t\t\t\t\t\tBatch 800/1563 Discriminator Loss: 0.5637 Generator Loss: 1.1810\n",
            "Epoch [1/10]\t\t\t\t\t\tBatch 900/1563 Discriminator Loss: 0.6197 Generator Loss: 1.0147\n",
            "Epoch [1/10]\t\t\t\t\t\tBatch 1000/1563 Discriminator Loss: 0.5726 Generator Loss: 1.1422\n",
            "Epoch [1/10]\t\t\t\t\t\tBatch 1100/1563 Discriminator Loss: 0.5148 Generator Loss: 1.0659\n",
            "Epoch [1/10]\t\t\t\t\t\tBatch 1200/1563 Discriminator Loss: 0.6341 Generator Loss: 0.6830\n",
            "Epoch [1/10]\t\t\t\t\t\tBatch 1300/1563 Discriminator Loss: 0.5559 Generator Loss: 1.2438\n",
            "Epoch [1/10]\t\t\t\t\t\tBatch 1400/1563 Discriminator Loss: 0.5276 Generator Loss: 1.1053\n",
            "Epoch [1/10]\t\t\t\t\t\tBatch 1500/1563 Discriminator Loss: 0.5959 Generator Loss: 1.1149\n",
            "Epoch [2/10]\t\t\t\t\t\tBatch 100/1563 Discriminator Loss: 0.7849 Generator Loss: 0.9809\n",
            "Epoch [2/10]\t\t\t\t\t\tBatch 200/1563 Discriminator Loss: 0.5624 Generator Loss: 1.1962\n",
            "Epoch [2/10]\t\t\t\t\t\tBatch 300/1563 Discriminator Loss: 0.5868 Generator Loss: 1.1788\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-2afb45865af7>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m                 \u001b[0;31m# Generate a batch of images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m                 \u001b[0mgen_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m                 \u001b[0;31m# Adversarial loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-dd58efb2bcfd>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, z)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m                 \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/upsampling.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         return F.interpolate(input, self.size, self.scale_factor, self.mode, self.align_corners,\n\u001b[0m\u001b[1;32m    157\u001b[0m                              recompute_scale_factor=self.recompute_scale_factor)\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36minterpolate\u001b[0;34m(input, size, scale_factor, mode, align_corners, recompute_scale_factor, antialias)\u001b[0m\n\u001b[1;32m   3929\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupsample_nearest1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_factors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3930\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"nearest\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3931\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupsample_nearest2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_factors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3932\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m5\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"nearest\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3933\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupsample_nearest3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_factors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "\tfor i, batch in enumerate(dataloader):\n",
        "\t# Convert list to tensor\n",
        "\t\treal_images = batch[0].to(device)\n",
        "\n",
        "\t\t# Adversarial ground truths\n",
        "\t\tvalid = torch.ones(real_images.size(0), 1, device=device)\n",
        "\t\tfake = torch.zeros(real_images.size(0), 1, device=device)\n",
        "\n",
        "\t\t# Configure input\n",
        "\t\treal_images = real_images.to(device)\n",
        "\n",
        "\t\t# ---------------------\n",
        "\t\t# Train Discriminator\n",
        "\t\t# ---------------------\n",
        "\n",
        "\t\toptimizer_D.zero_grad()\n",
        "\n",
        "\t\t# Sample noise as generator input\n",
        "\t\tz = torch.randn(real_images.size(0), latent_dim, device=device)\n",
        "\n",
        "\t\t# Generate a batch of images\n",
        "\t\tfake_images = generator(z)\n",
        "\n",
        "\t\t# Measure discriminator's ability\n",
        "\t\t# to classify real and fake images\n",
        "\t\treal_loss = adversarial_loss(discriminator\\\n",
        "\t\t\t\t\t\t\t\t\t(real_images), valid)\n",
        "\t\tfake_loss = adversarial_loss(discriminator\\\n",
        "\t\t\t\t\t\t\t\t\t(fake_images.detach()), fake)\n",
        "\t\td_loss = (real_loss + fake_loss) / 2\n",
        "\n",
        "\t\t# Backward pass and optimize\n",
        "\t\td_loss.backward()\n",
        "\t\toptimizer_D.step()\n",
        "\n",
        "\t\t# -----------------\n",
        "\t\t# Train Generator\n",
        "\t\t# -----------------\n",
        "\n",
        "\t\toptimizer_G.zero_grad()\n",
        "\n",
        "\t\t# Generate a batch of images\n",
        "\t\tgen_images = generator(z)\n",
        "\n",
        "\t\t# Adversarial loss\n",
        "\t\tg_loss = adversarial_loss(discriminator(gen_images), valid)\n",
        "\n",
        "\t\t# Backward pass and optimize\n",
        "\t\tg_loss.backward()\n",
        "\t\toptimizer_G.step()\n",
        "\n",
        "\t\t# ---------------------\n",
        "\t\t# Progress Monitoring\n",
        "\t\t# ---------------------\n",
        "\n",
        "\t\tif (i + 1) % 100 == 0:\n",
        "\t\t\tprint(\n",
        "\t\t\t\tf\"Epoch [{epoch+1}/{num_epochs}]\\\n",
        "\t\t\t\t\t\tBatch {i+1}/{len(dataloader)} \"\n",
        "\t\t\t\tf\"Discriminator Loss: {d_loss.item():.4f} \"\n",
        "\t\t\t\tf\"Generator Loss: {g_loss.item():.4f}\"\n",
        "\t\t\t)\n",
        "\n",
        "\t# Save generated images for every epoch\n",
        "\tif (epoch + 1) % 10 == 0:\n",
        "\t\twith torch.no_grad():\n",
        "\t\t\tz = torch.randn(16, latent_dim, device=device)\n",
        "\t\t\tgenerated = generator(z).detach().cpu()\n",
        "\t\t\tgrid = torchvision.utils.make_grid(generated,\\\n",
        "\t\t\t\t\t\t\t\t\t\tnrow=4, normalize=True)\n",
        "\t\t\tplt.imshow(np.transpose(grid, (1, 2, 0)))\n",
        "\t\t\tplt.axis(\"off\")\n",
        "\t\t\tplt.show()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}